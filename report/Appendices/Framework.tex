% Appendix A

\chapter{Developer Guide} % Main appendix title
\label{framework}
The implementation is made to be modular. Adding new algorithms or features is as simple as adding a new class. 

\section{Machine learning module}
New machine learning algorithms can be added to the implementation by creating a new class and placing the class in the \textit{ml.py} file. A base class, \textbf{MLAlgorithm}, has to be inherited from and two methods have to be implemented: \\
\begin{python}
class SomeAlgorithm(MLAlgorithm):
    def train(self, data_set, target_set=None):
        data_set is an array of features
        target_set is an array of labels
            (or none for unsupervised learning)

    def predict(self, sample, corr=None):
        sample is a feature that is going 
            to be used for prediction
        corr is the correct label that 
            should be predicted
\end{python}

\section{Feature module}
A feature class is used to parse a flow. The \textbf{Flow} class is a simple "struct" like class that contains the necessary member variables for a flow. The \textbf{Flows} class is a collection of flows. To make a new featureClass, a base class, \textbf{BasicFeature}, has to be inherited from and two methods have to be implemented:\\

\begin{python}
class FlowFeature(BasicFeature):
    def __init__(self, file):
        file is a json file that may contain extra 
        information to make a featureClass 
        more reusable
        
    def make_record(self, flow):
        flow is an instance of the Flow class
        return an array of numbers to be fed 
            to a machine learning algorithm
\end{python}

\section{Loader module}
The loader module is responsible for loading the flows from any external source. The exernal source could be a text file or a SQL database. The new class should be placed in the \textit{loader.py} file. The loader class should be defined using a load and a get\_netflow method. The parameters of load can be chosen at will since the loading has to be implemented in a training class. \\
\begin{python}
class LoaderName:
    def load(self, ...):
        load the data from the source
        
    def get_netflow(self):
        return the netflow
\end{python}

\section{Prediction Module}
\noindent If a new type of loader needs to be used in the check-sets, a class has to be added to the Prediction module in the \textit{prediction\_type.py} file.  A base class, \textbf{PredictionLoader}, has to be inherited from and a method has to be implemented: "load(self, data)". "data" is a dictionary loaded from the config file.\\
\begin{python}
class PredictionFile(PredictionLoader):
    def load(self, data):
        return the netflow
\end{python}

\section{Training module}
The training module is responsible for all training classes. New types of training can be added to the implementation by creating a new class and placing the class in the \textit{train.py} file. A base class, \textbf{Trainer}, has to be inherited from and a method has to be implemented. The method has several parameters. "algorithm" is an instance of a machine learning algorithm. "data" is a dictionary loaded from the config file from data-sets. "feature" is an instance of the selected featureClass. "good\_labels" is a list of all labels that are considered normal behaviour. \\
\\
\textit{self.default} is a method implemented in the Trainer class. This method loads the file using the specified loader and file. Afterwards it extracts the features and feeds them to the machine learning algorithm. \\
\begin{python}
class TrainerName(Trainer):

    def train(self, algorithm, data, feature, 
                                  good_labels):
        load the data
        return self.default(algorithm, loader, 
                                    feature, file)
\end{python}

\section{Results module}
The results module is the biggest module and is constructed from three files. The first file, \textit{logger.py}, contains the main \textbf{Logger} class. These methods write to the log file that is specified in the config file. \\
\\
\textit{visualise.py} contains all methods that are used to visualise the machine learning algorithms. These visualisation methods can be injected into the program execution by using them in a machine learning class. This is required since the visualisation methods depend highly on the "train" and "predict" methods of the machine learning algorithms. \\
\\
Finally, the \textit{results.py} file receives all output from the prediction algorithms. They can filter out predictions that are considered normal behaviour and evaluate the machine learning algorithm using the amount of false positives and negatives. 

\section{Other}
\textit{main.py} and \textit{testing.py} are the main entry-points of the program. \textit{main.py} puts together all different components to make the program execute. The \textit{config.py} file is responsible for parsing the config file. Any new additions to the config file need to be reflected in this file. \textit{predictor.py} is the file responsible for running the different check-sets. \textit{sniffer.py} contains the small implementation of the sniffer, the real-time intrusion detection implementation. 
